"""
Scipy version > 0.18 is needed, due to 'mode' option from scipy.misc.imread function
"""

import os
import glob
import h5py
import random
import matplotlib.pyplot as plt
from sklearn.feature_extraction.image import PatchExtractor


import imageio
import scipy.ndimage
import numpy as np

import tensorflow as tf

class BatchFeeder():
    
    def __init__(self):
        
        # indicator of the batches
        self.i = 0
        
        # working directory of 'Spring2019-Proj3-grp1'
        pwd = os.path.dirname(os.path.dirname(os.getcwd()))
        # set the working directory of processed data
        dataprocessed_wd = os.path.join(pwd, "output", "dataprocessed")
        if not os.path.exists(dataprocessed_wd):
            os.makedirs(dataprocessed_wd)
        
        print("Loading the training images...")
        self.train_image_lr_raw, self.train_image_hr = load_image(is_train=True)

        test_wd = os.path.join(dataprocessed_wd,"train_image_lr_0.npy")
        if os.path.exists(test_wd):
            self.train_image_lr = read_data(path = dataprocessed_wd)
        else:
            self.train_image_lr = np.array(interpolate_image(self.train_image_lr_raw))
            save_data(data = np.array(self.train_image_lr), path = dataprocessed_wd, n = 200)
                      
        print("Loading the testing data...")
        self.test_image_lr_raw, self.test_image_hr = load_image(is_train=False)
        self.test_image_lr = interpolate_image(self.test_image_lr_raw)
    
    def patch_image(self, patch_side = 29, max_patches=20):
        print("Patchify the training images...")
        self.train_lr, self.train_hr = extract_patch((self.train_image_lr, self.train_image_hr), patch_side=patch_side, max_patches=max_patches)
        self.test_lr, self.test_hr = extract_patch((self.test_image_lr, self.test_image_hr), patch_side=200, max_patches=4)
        
    def next_batch(self, batch_size):
        
        lr = self.train_lr[self.i:self.i+batch_size]
        hr = self.train_hr[self.i:self.i+batch_size]
        self.i = (self.i+batch_size) % len(self.train_hr)
        
        return lr, hr
  

def load_image(is_train=True):
  """
    Load jpg format image file in RGB mode.
    
    Input: is_train, True means you are loading training images
    Return: image_lr, image_hr
  """
  image_lr = []
  image_hr = []

  # working directory of 'Spring2019-Proj3-grp1'
  wd = os.path.dirname(os.path.dirname(os.getcwd()))

  if is_train:
    data_dir = os.path.join(wd, 'data', 'train_set')
  else:
    data_dir = os.path.join(wd, 'data', 'test_set')

  path_lr = glob.glob(os.path.join(data_dir, 'LR', '*.jpg'))
  path_hr = glob.glob(os.path.join(data_dir, 'HR', '*.jpg'))

  for i in range(len(path_lr)):
    image_lr.append(imageio.imread(path_lr[i], as_gray=False, pilmode="RGB").astype(np.float32)/255.)
    image_hr.append(imageio.imread(path_hr[i], as_gray=False, pilmode="RGB").astype(np.float32)/255.)

  return np.array(image_lr), np.array(image_hr)

def extract_patch(images, patch_side=33, max_patches=20):
  """
    Extracts patches from a collection of images.

    'patch': refer to patch generated by single image
    'images': refer to the set of all images
    'patches': refer to the patches generated by the set of all images

    Input: images = (image_lr, image_hr)
    Return: patches_lr, patches_hr
  """
  image_lr, image_hr = images
  N = len(image_lr)

  patches_lr = np.empty([0,patch_side, patch_side, 3])
  patches_hr = np.empty([0,patch_side, patch_side, 3])

  patchextractor = PatchExtractor()
  patchextractor.set_params(patch_size=(patch_side, patch_side), max_patches=max_patches)

  for i in range(N):
    # set the ramdom sate
    randint = np.random.randint(0, 2**16-1)

    # patchify the low resolution images
    patchextractor.set_params(random_state=randint)
    # the low resolution need to be bicubiced
    patch_lr = patchextractor.transform(np.expand_dims(image_lr[i], axis=0))
    patches_lr = np.append(patches_lr, patch_lr, axis = 0)

    # patchify the low resolution images
    patchextractor.set_params(random_state=randint)
    patch_hr = patchextractor.transform(np.expand_dims(image_hr[i], axis=0))
    patches_hr = np.append(patches_hr, patch_hr, axis = 0)

  return patches_lr, patches_hr

def interpolate_image(images, scale=2):

  N = len(images)
  images_scaled = []

  for i in range(N):
    images_scaled.append(scipy.ndimage.interpolation.zoom(images[i], (scale, scale, 1), prefilter=False))

  return np.array(images_scaled)
    

def save_data(data, path, n = 200):
    
    N = len(data)
    K = np.ceil(N/n).astype(int)
    
    for i in range(K):
        trainilr_wdi = os.path.join(path, "train_image_lr_"+str(i)+".npy")
        np.save(trainilr_wdi, data[i*n:(i+1)*n])

def read_data(path):
    
    result = np.array([])
    
    paths = glob.glob(os.path.join(path, 'train_image_lr_*.npy'))
    
    K = len(paths)
    for i in range(K):
        result = np.append(result, np.load(paths[i]))
    
    return result