"""
Scipy version > 0.18 is needed, due to 'mode' option from scipy.misc.imread function
"""

import os
import glob
import h5py
import random
import matplotlib.pyplot as plt
from sklearn.feature_extraction.image import PatchExtractor


import imageio
import scipy.ndimage
import numpy as np

import tensorflow as tf

class BatchFeeder():
    
    def __init__(self):
        
        # indicator of the batches
        self.i = 0
        
        # working directory of 'Spring2019-Proj3-grp1'
        pwd = os.path.dirname(os.path.dirname(os.getcwd()))
        # set the working directory of processed data
        dataprocessed_wd = os.path.join(pwd, "output", "dataprocessed")
        if not os.path.exists(dataprocessed_wd):
            os.makedirs(dataprocessed_wd)
        
        print("Loading the training images...")
        self.train_image_lr_raw, self.train_image_hr = load_image(is_train=True)

        test_wd = os.path.join(dataprocessed_wd,"train_image_lr_0.npy")
        if os.path.exists(test_wd):
            self.train_image_lr = read_data(path = dataprocessed_wd)
        else:
            self.train_image_lr = np.array(interpolate_image(self.train_image_lr_raw))
            save_data(data = np.array(self.train_image_lr), path = dataprocessed_wd, n = 200)
                      
        print("Loading the testing data...")
        self.test_image_lr_raw, self.test_image_hr = load_image(is_train=False)
        self.test_image_lr = interpolate_image(self.test_image_lr_raw)
    
    def patch_image(self, patch_side = 29, max_patches=20):
        print("Patchify the training images...")
        self.train_lr, self.train_hr = extract_patch((self.train_image_lr, self.train_image_hr), patch_side=patch_side, max_patches=max_patches)
        self.test_lr, self.test_hr = extract_patch((self.test_image_lr, self.test_image_hr), patch_side=200, max_patches=4)
        
    def next_batch(self, batch_size):
        
        lr = self.train_lr[self.i:self.i+batch_size]
        hr = self.train_hr[self.i:self.i+batch_size]
        self.i = (self.i+batch_size) % len(self.train_hr)
        
        return lr, hr
  

def load_image(is_train=True):
  """
    Load jpg format image file in RGB mode.
    
    Input: is_train, True means you are loading training images
    Return: image_lr, image_hr
  """
  image_lr = []
  image_hr = []

  # working directory of 'Spring2019-Proj3-grp1'
  wd = os.path.dirname(os.path.dirname(os.getcwd()))

  if is_train:
    data_dir = os.path.join(wd, 'data', 'train_set')
  else:
    data_dir = os.path.join(wd, 'data', 'test_set')

  path_lr = glob.glob(os.path.join(data_dir, 'LR', '*.jpg'))
  path_hr = glob.glob(os.path.join(data_dir, 'HR', '*.jpg'))

  for i in range(len(path_lr)):
    image_lr.append(imageio.imread(path_lr[i], as_gray=False, pilmode="RGB").astype(np.float32)/255.)
    image_hr.append(imageio.imread(path_hr[i], as_gray=False, pilmode="RGB").astype(np.float32)/255.)

  return np.array(image_lr), np.array(image_hr)

def extract_patch(images, patch_side=33, max_patches=20):
  """
    Extracts patches from a collection of images.

    'patch': refer to patch generated by single image
    'images': refer to the set of all images
    'patches': refer to the patches generated by the set of all images

    Input: images = (image_lr, image_hr)
    Return: patches_lr, patches_hr
  """
  image_lr, image_hr = images
  N = len(image_lr)

  patches_lr = np.empty([0,patch_side, patch_side, 3])
  patches_hr = np.empty([0,patch_side, patch_side, 3])

  patchextractor = PatchExtractor()
  patchextractor.set_params(patch_size=(patch_side, patch_side), max_patches=max_patches)

  for i in range(N):
    # set the ramdom sate
    randint = np.random.randint(0, 2**16-1)

    # patchify the low resolution images
    patchextractor.set_params(random_state=randint)
    # the low resolution need to be bicubiced
    patch_lr = patchextractor.transform(np.expand_dims(image_lr[i], axis=0))
    patches_lr = np.append(patches_lr, patch_lr, axis = 0)

    # patchify the low resolution images
    patchextractor.set_params(random_state=randint)
    patch_hr = patchextractor.transform(np.expand_dims(image_hr[i], axis=0))
    patches_hr = np.append(patches_hr, patch_hr, axis = 0)

  return patches_lr, patches_hr

def interpolate_image(images, scale=2):

  N = len(images)
  images_scaled = []

  for i in range(N):
    images_scaled.append(scipy.ndimage.interpolation.zoom(images[i], (scale, scale, 1), prefilter=False))

  return np.array(images_scaled)
    

def save_data(data, path, n = 200):
    
    N = len(data)
    K = np.ceil(N/n).astype(int)
    
    for i in range(K):
        trainilr_wdi = os.path.join(path, "train_image_lr_"+str(i)+".npy")
        np.save(trainilr_wdi, data[i*n:(i+1)*n])

def read_data(path):
    
    result = np.array([])
    
    paths = glob.glob(os.path.join(path, 'train_image_lr_*.npy'))
    
    K = len(paths)
    for i in range(K):
        result = np.append(result, np.load(paths[i]))
    
    return result









def patch_train(images, patch_side = 29, is_lr = True, scale=2):

  N = len(images)
  patches = np.empty([0,patch_side, patch_side, 3])

  for i in range(40):
    # only bicubic the low resolution pictures
    if is_lr:
      image = scipy.ndimage.interpolation.zoom(images[i], (scale, scale, 1), prefilter=False)
    else:
      image = images[i]
    # now, the size of lr and hr are the size
    # crop the lr and hr pictures
    h, w, _ = image.shape
    h = h - np.mod(h, patch_side)
    w = w - np.mod(w, patch_side)
    image = image[0:h, 0:w, :]

    # patch the single images
    image_patched = patch_image(image, patch_side)
    
    # aggregrate all patches
    patches = np.append(patches, image_patched, axis = 0)
  
  return patches

def patch_channel(channel, patch_side):
    
    h, w = channel.shape
    nh = int(h/patch_side)
    nw = int(w/patch_side)
    
    shape = [nh, nw, patch_side, patch_side]
    strides = channel.itemsize*np.array([patch_side*w,patch_side,w,1])
    
    return np.lib.stride_tricks.as_strided(channel, shape=shape, strides=strides)

def patch_image(image, patch_side):
    
    r = image[:,:,0].astype(np.float32)
    g = image[:,:,1].astype(np.float32)
    b = image[:,:,2].astype(np.float32)
    
    r_patched = patch_channel(r, patch_side)
    g_patched = patch_channel(g, patch_side)
    b_patched = patch_channel(b, patch_side)
    
    image_patched = np.stack((r_patched, g_patched,b_patched), axis=4)
    
    return image_patched.reshape(-1, patch_side, patch_side, 3)





  


def imsave(image, path):
  return scipy.misc.imsave(path, image)

def merge(images, size):
  h, w = images.shape[1], images.shape[2]
  img = np.zeros((h*size[0], w*size[1], 1))
  for idx, image in enumerate(images):
    i = idx % size[1]
    j = idx // size[1]
    img[j*h:j*h+h, i*w:i*w+w, :] = image

  return img




def make_data(sess, data, label):
  """
  Make input data as h5 file format
  Depending on 'is_train' (flag value), savepath would be changed.
  """
  if FLAGS.is_train:
    savepath = os.path.join(os.getcwd(), 'checkpoint/train.h5')
  else:
    savepath = os.path.join(os.getcwd(), 'checkpoint/test.h5')

  with h5py.File(savepath, 'w') as hf:
    hf.create_dataset('data', data=data)
    hf.create_dataset('label', data=label)